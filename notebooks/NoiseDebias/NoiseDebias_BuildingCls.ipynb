{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,progressbar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "sys.path.insert(1, '/home/amarins/ComponentSeparation/gmca/scripts')\n",
    "import Extension4BINGO as cs\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "################   GENERAL INFORMATIONS   #############\n",
    "#######################################################\n",
    "n_realizations   = 3 #If you want to use all realizations, please, put -1\n",
    "method           = \"ICA\"\n",
    "wtransform       = [\"identity\"]\n",
    "maps_wout_mean   = True\n",
    "apply_mask       = False\n",
    "add_noise        = False\n",
    "\n",
    "#######################################################\n",
    "################   WAVELETS PARAMETERS   ##############\n",
    "#######################################################\n",
    "#####\n",
    "# The main aim is to have:\n",
    "# Starlet, Axisymmetric, spin-Directional, Wavelets Standard from PyWavelets, Curvelets, Counturlets, Shearlets, Ridgelets and so on\n",
    "#####\n",
    "J     = 1  #number of scales\n",
    "use_c = True  # if you will use wavelet scale in the analysis\n",
    "\n",
    "##############\n",
    "# S2LET code\n",
    "# If you to use wtransforms by S2Let code, please, fill in the variables below:\n",
    "L        = -1 #If you write L<0, it will use L=3*nside\n",
    "J_min    = 1\n",
    "B        = 5     \n",
    "N        = 3  # Number of directions (This is for Directional only)\n",
    "spin     = 0  # set to 0 for temperature. if non-zero, plotting routines must be changed! (This is for Directional only)\n",
    "upsample = 0  # 1 means all scales at full resolution L # 0 means multiresolution wavelet transform (This is for Directional only)\n",
    "# In the S2LET code, J scales is defined by code and not by J above.\n",
    "\n",
    "##############\n",
    "# PyWavelets\n",
    "Jpwt     = 1 #number of scales\n",
    "pywttype = \"haar\" \n",
    "\n",
    "##############\n",
    "# Needlets\n",
    "needlet   = \"mexican\" # either mexican(=gaussian), or standard\n",
    "Bneed     = 1.15            # filter is defined by function b(l/B**j), where j=freq\n",
    "p         = 0.9             # this value is only for mexican needlet\n",
    "fneed     = [15,24,30,34]   # number of freqs will be the number of scales (wavelet maps). Center of i-band will be approached given by l_center_i = B**freq_i (p=0)\n",
    "lmax_need = -1\n",
    "\n",
    "##############\n",
    "# Curvelets\n",
    "##############\n",
    "# Counturlets\n",
    "##############\n",
    "# Shearlets\n",
    "##############\n",
    "# Ridgelets\n",
    "\n",
    "#######################################################\n",
    "#### COMPONENT SEPARATION #############################\n",
    "#######################################################\n",
    "n_s = 1  #number of sources to be estimated\n",
    "#Warning! if this one is 1, it's impossible build projection maps\n",
    "\n",
    "######## FastICA PARAMETERS \n",
    "whiten = True  ######## Maintain True\n",
    "fun = 'logcosh' #exp,logcosh or\n",
    "max_iter = 20\n",
    "tol = 0.01\n",
    "\n",
    "######## GMCA PARAMETERS   \n",
    "mints = 0.05 # min threshold (what is sparse compared to noise?)\n",
    "nmax  = 100 # number of iterations (usually 100 is safe)\n",
    "L0    = 0   # switch between L0 norm (1) or L1 norm (0)\n",
    "\n",
    "#######################################################\n",
    "AInit     = None\n",
    "ColFixed  = None\n",
    "whitening = False\n",
    "epsi      = 1e-3\n",
    "verbose   = False\n",
    "#GMCAExtension\n",
    "div          = 1 #  J+1  #J/div will should be even number\n",
    "without_covx = True # if your mixmatrix estimated will use covariance matrix of the observer data with ponderation\n",
    "# 0 <= noise factor <= 1\n",
    "#noise_factor = 1  <-------------- Preciso que os mapas sejam todos separados\n",
    "\n",
    "#######################################################\n",
    "################   DEBIAS PARAMETERS   ################\n",
    "#######################################################\n",
    "seed_used = 10     #If False, it will be chosen a random realization. Otherwise, it is necessary to write which realization that will be used. For example, if you want to use L10, it is necessary you to write 10 (it's string). Also, if you chose realizaton out of set, it will be chosen a random value.\n",
    "\n",
    "#######################################################\n",
    "################   PATHS PARAMETERS   #################\n",
    "#######################################################\n",
    "#path outputs\n",
    "pathout       = \"/home/amarins/ComponentSeparation/gmca/outputs/Gtest_addCommand\" #Put here your path to the output cls\n",
    "cl_type_save  = \"reconstruction\" #You should choice between reconstruction or residuals cls values\n",
    "savefits      = True# or False\n",
    "#######################################################\n",
    "################   NAME FILES PARAMETERS   ############\n",
    "#######################################################\n",
    "# Name of FITS files inside of the pathmaps\n",
    "name_mask = \"Mask_Bin.fits\" #put this file in the same directory of the other maps\n",
    "\n",
    "#Directory names\n",
    "dir_observed  = \"/media/new-drive/CS_Cubes/White_Noise/input_wn\"\n",
    "dir_mask      = \"/media/new-drive/amarins/maps/mask\"\n",
    "dir_prior     = \"/media/new-drive/CS_Cubes/White_Noise/prior_wn\"\n",
    "dir_noise     = \"/media/new-drive/CS_Cubes/Only_White_Noise_Masked\"\n",
    "dir_pure      = \"/media/new-drive/CS_Cubes/No_Noise/prior_nn\"\n",
    "dir_projprior = \"/media/new-drive/CS_Cubes/White_Noise/prior_wn\"\n",
    "dir_projnoise = \"/media/new-drive/CS_Cubes/Only_White_Noise_Masked\"\n",
    "dir_projpure  = \"/media/new-drive/Cs_cubes/No_Noise/prior_nn\"\n",
    "\n",
    "#######################################################\n",
    "restart = True\n",
    "#if you were running the code and it broke, and you used \"n_realizations\" <total, the next run will assume restart = True, because it's impossible to know which nseed you used\n",
    "#warning: if you don't have the directories and put \"restart=False\" code wont be work. Please, put \"True\" to create directories and to run.\n",
    "#You cant create \"proj\" directories if you dont have all others directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_maps = pd.Series({\"without_mean\":maps_wout_mean, \"apply_mask\":apply_mask, \"add_noise\":add_noise, \"cl_type_save\":cl_type_save})\n",
    "params_CS   = pd.Series({\"restart\":restart,\"n_realizations\":n_realizations, \"method\":method,\n",
    "                         \"A_ini\":AInit, \"ColFixed\":ColFixed, \"whitening\":whitening, \"epsi\":epsi, \"verbose\":verbose, \"ns\":n_s, \"mints\":mints,\"nmax\":nmax, \"L0\":L0, \"division\":div, \"without_covx\":without_covx, \"seed_used\":seed_used,\n",
    "                         \"whiten\":whiten, \"fun\":fun, \"max_iter\":max_iter, \"tol\":tol})\n",
    "params_WT   = pd.Series({\"wtransform\":np.asarray(wtransform), \"use_c\":use_c, \"J\":J, \n",
    "                         \"L\":L, \"Jmin\":J_min, \"B\": B, \"N\":N, \"spin\":spin, \"upsample\":upsample,\n",
    "                         \"Jpwt\":Jpwt, \"pywttype\":pywttype.lower(),\n",
    "                         \"needlet\":needlet, \"Bneed\":Bneed, \"p\":p, \"fneed\": fneed, \"lmax_need\":lmax_need})\n",
    "params_path = pd.Series({\"pathout\":pathout, \"dir_observed\":dir_observed, \"dir_mask\":dir_mask, \"dir_noise\":dir_noise, \"dir_prior\":dir_prior,\"dir_pure\":dir_pure, \"name_mask\":name_mask})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Foregrounds + HI + Noise\n",
    "$C_{\\ell}^{\\textrm{FG+HI+N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:08:12 Time:  0:08:12\n"
     ]
    }
   ],
   "source": [
    "names, nseed0 = cs.nsamples(params_CS,params_path,path=params_path.dir_observed, listdir=\"21cm\")\n",
    "params_maps[\"getdata\"] = \"observed\"\n",
    "subdirs = cs.checkdir(params_path.pathout, subdirs=[\"21cm\",\"foregrounds\",\"mixmatrix\"],restart=params_CS[\"restart\"])\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_observed\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    X = cs.maps2CSmaps(X, params_wt, params_cs)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed0[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)\n",
    "    #del X\n",
    "clear_output(wait=True)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise\n",
    "$C_{\\ell}^{\\textrm{N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:04:31 Time:  0:04:31\n"
     ]
    }
   ],
   "source": [
    "params_maps[\"getdata\"] = \"noise\"\n",
    "subdirs                = [\"noise\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "names, nseed           = cs.nsamples(params_CS,params_path,path=params_path.dir_noise, listdir=params_maps[\"getdata\"],nseed_used=nseed0)\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_noise\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior\n",
    "$C_{\\ell}^{\\textrm{prior}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:03:57 Time:  0:03:57\n"
     ]
    }
   ],
   "source": [
    "params_maps[\"getdata\"] = \"prior\"\n",
    "subdirs = [\"prior\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "names, nseed = cs.nsamples(params_CS,params_path,path=params_path.dir_prior, listdir=params_maps[\"getdata\"],nseed_used=nseed0)\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)    \n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i) \n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_prior\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)    \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm pure\n",
    "$C_{\\ell}^{\\textrm{pure}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:03:48 Time:  0:03:48\n"
     ]
    }
   ],
   "source": [
    "params_maps[\"getdata\"] = \"pure\"\n",
    "subdirs = [\"pure\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "names, nseed = cs.nsamples(params_CS,params_path,path=params_path.dir_pure, listdir=params_maps[\"getdata\"],nseed_used=nseed0)\n",
    "    \n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    time0 = time.time()\n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_pure\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)    \n",
    "    \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm proj pure\n",
    "$C_{\\ell}^{\\textrm{proj pure}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:03:55 Time:  0:03:55\n"
     ]
    }
   ],
   "source": [
    "params_maps[\"getdata\"] = \"pure\"\n",
    "subdirs = [\"projpure\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "names, nseed = cs.nsamples(params_CS,params_path,path=params_path.dir_pure, listdir=\"proj\"+params_maps[\"getdata\"],nseed_used=nseed0)\n",
    "\n",
    "if nseed0[nseed0==params_CS.seed_used].size>0:\n",
    "    L0 = \"L{}\".format(params_CS.seed_used)\n",
    "else:\n",
    "    L0 = \"L{}\".format(np.random.choice(nseed0,size=1)[0])\n",
    "\n",
    "A   = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_pure\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)    \n",
    "\n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm  proj noise\n",
    "$C_{\\ell}^{\\textrm{proj noise}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:03:48 Time:  0:03:48\n"
     ]
    }
   ],
   "source": [
    "params_maps[\"getdata\"] = \"noise\"\n",
    "subdirs = [\"projnoise\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "names, nseed = cs.nsamples(params_CS,params_path,path=params_path.dir_noise, listdir=\"proj\"+params_maps[\"getdata\"],nseed_used=nseed0)\n",
    "\n",
    "if nseed0[nseed0==params_CS.seed_used].size>0:\n",
    "    L0 = \"L{}\".format(params_CS.seed_used)\n",
    "else:\n",
    "    L0 = \"L{}\".format(np.random.choice(nseed0,size=1)[0])\n",
    "\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_noise\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)    \n",
    "\n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm  proj prior\n",
    "$C_{\\ell}^{\\textrm{proj prior}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3 of 3) |##########################| Elapsed Time: 0:03:51 Time:  0:03:51\n"
     ]
    }
   ],
   "source": [
    "params_maps[\"getdata\"] = \"prior\"\n",
    "subdirs = [\"projprior\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "names, nseed = cs.nsamples(params_CS,params_path,path=params_path.dir_prior, listdir=\"proj\"+params_maps[\"getdata\"],nseed_used=nseed0)\n",
    "\n",
    "\n",
    "if nseed0[nseed0==params_CS.seed_used].size>0:\n",
    "    L0 = \"L{}\".format(params_CS.seed_used)\n",
    "else:\n",
    "    L0 = \"L{}\".format(np.random.choice(nseed0,size=1)[0]) \n",
    "\n",
    "A = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    params_cs, params_wt = cs.load(params_CS,params_WT)\n",
    "    params_path[\"name_prior\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_wt, params_CS=params_cs, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving used parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_CS[\"seed_used\"]=L0\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "params_maps.to_csv(os.path.join(params_path.pathout,\"map_parameters.txt\") , sep=':', index=True)\n",
    "params_CS.to_csv(  os.path.join(params_path.pathout,\"CS_parameters.txt\")  , sep=':', index=True)\n",
    "params_WT.to_csv(  os.path.join(params_path.pathout,\"WT_parameters.txt\")  , sep=':', index=True)\n",
    "params_path.to_csv(os.path.join(params_path.pathout,\"path_parameters.txt\"), sep=':', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
